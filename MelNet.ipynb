{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MelNet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1FNV13EH4VfIlLO8Ff0ZeCDXfuZTnTq8p","authorship_tag":"ABX9TyM8cOmcEOmoYmalA30hsdpB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"17p0Hfx3oNzs"},"source":["# MelNet  -> Implemented using tensorflow : https://arxiv.org/pdf/1906.01083.pdf\n","# Strongly advice to read paper to understand code.\n","# Only does Unconditional generation at the moment\n","# Further updates for conditional generation later\n","#%tensorflow 1\n","from tensorflow.keras.layers import LSTM,GRU, Dense, Input, Lambda, BatchNormalization, Input, Concatenate\n","#from keras.layers import Conv2D+\n","import tensorflow.keras.backend as K\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n","import tensorflow_probability as tfp\n","import gc\n","import math\n","from tqdm import tqdm\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DgnOjGakuGU"},"source":["import math\n","import json\n","import time\n","import gc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsA1ep9IAzhn","executionInfo":{"status":"ok","timestamp":1608489759026,"user_tz":360,"elapsed":9397,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"6b0ae3ec-e0d8-4f0c-fddc-8374f224b467"},"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 10.6 GB  | Proc size: 3.3 GB\n","GPU RAM Free: 502MB | Used: 14577MB | Util  97% | Total 15079MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R8FnFbkwDhcj"},"source":["  tfd =  tfp.distributions #Access to different statistical distributions. We use the tf.MixtureSameFamily"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZyHlP4z4EBmZ"},"source":["Main MelNet Function"]},{"cell_type":"code","metadata":{"id":"gZrF2MK9CCpN","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1608488929995,"user_tz":360,"elapsed":11359,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"95d6b43f-1618-4ed4-81e1-f6bf6647dda3"},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"h6ELWrPfD_r_"},"source":["#Create FrequencyDelayedStack and TimeDelayedStack functions"]},{"cell_type":"code","metadata":{"id":"wn4EcHpR3qRR"},"source":["DESTINATION_PATH= '/content/drive/MyDrive/Deep Learning/MelNet Implementation/Training data'\n","DATA_PATH = '/content/drive/MyDrive/Deep Learning/MelNet Implementation/output'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwMmCt6DeIgl"},"source":["'''\n","  MelNet is an autoregressive (audio generative) model that takes mel spectogram as input and outputs the distribution parameters (mean,std) responsible for \n","  the input. It models each input using a gaussian mixture model. It maximizes the marginal likelihood of the input samples.\n","'''\n","\n","def gaussian_mixture_loss(label_spect, mu , std , alpha):\n","  '''Calculates the loss by sampling from the distribution parameterized by the model output. It takes the model input and output(mu,std,alpha)\n","  and calculates the loss.'''\n","  # Dimensions: (batch_size, dim_f1, dim_t1, num of mixture)\n","\n","  # mu = tensor_out[:, 1, :]\n","  # sigma = tensor_out[:, 2, :]\n","  # alpha = tensor_out[:, 0, :]\n","\n","  gm = tfd.MixtureSameFamily(\n","      mixture_distribution = tfd.Categorical(\n","          probs=alpha),\n","          components_distribution = tfd.Normal(loc = mu, scale = std))\n","  \n","  #log_loss = -tf.reduce_sum(gm.log_prob(tf.squeeze(label_spect)))\n","  log_loss = -tf.math.reduce_mean(gm.log_prob(label_spect))\n","\n","  return log_loss\n","\n","\n","def sampling_gauss(mu, std , alpha):\n","  # Function to sample from distribution\n","  # Dimensions: (batch_size, dim_f1, dim_t1, num of mixture)\n","  gm = tfd.MixtureSameFamily(\n","      mixture_distribution = tfd.Categorical(\n","          probs=alpha), components_dsitribution=tfd.Normal(loc = mu, scale = std))\n","  \n","  return gm\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5D-VmJrTaYzv"},"source":["def sample_from_disribution(mu , std, alpha ,batch_size=1):\n","    # Sampling from a gaussian mixture model:\n","    \n","    dim_f = np.size(miut1, 1)\n","    dim_t = np.size(miut1, 2)\n","    #batch_size = np.size(miut1, 0)\n","    num_mixture = int(np.size(miut1, 3))\n","    # data dimensions : ( Batch_size , dim_f , dim_t,3k )\n","    # Apply transformation as in (3) (4) (5) to gaussian model:\n","    #output_tot = np.zeros((dim_f, dim_t))\n","    output_tot_batch_format = np.zeros((batch_size, dim_f, dim_t))\n","\n","    for batch_num in range(batch_size):\n","        sum_mixture = 0\n","        alpha_batch = alphat1[batch_num]\n","        miu_batch = miut1[batch_num]\n","        sigma_batch = sigmat1[batch_num]\n","        sum_alpha_batch = np.sum(alpha_batch, axis=2)\n","        \n","        out = np.zeros((dim_f, dim_t))\n","        if np.sum(1) > 0:\n","            for i in range(dim_f):\n","                for j in range(dim_t):\n","                    ind = np.random.choice(np.arange(0, num_mixture), p=np.ravel([alpha_batch[i, j, :]]))\n","                    out[i, j] = np.random.normal(miu_batch[i, j, ind], sigma_batch[i, j, ind])\n","\n","        #output_tot = np.append(output_tot, out, axis=1)\n","        output_tot_batch_format = np.append(output_tot_batch_format, np.expand_dims(out, axis=0), axis=0)\n","    return output_tot_batch_format\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"01V-WI2P1yns"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"XEfhz5zYLAO-"},"source":[" 10s, 22050hz   = 861 samples   431 samples\n","\n"," 15s, 22050hz   = 1291 samples  646 samples\n","\n"," 20s,22050hz   = 1724 samples   862 samples\n","\n"," 25s, 22050hz  = 2154 samples   1077 samples\n","\n"," 30s,18000hz  =  2110 samples   1055 samples\n","\n"," 30s, 22050hz  =  2584 samples  1292 samples\n"," 35s, 22050hz =  3015 samples   1507 samples\n"," \n","\n"," 45s, 18000hz  =  3184 samples  1582 samples\n","\n","45s, 22050hz  = 3876 samples,  1938 samples\n","\n"," 1 min,18000hz  = 4220 samples  2109 samples\n"," \n"," 1 min, 22050hz  = 5168 samples 2583 samples\n","\n","\n","  # when we perform stft, the number of time frames we get is:\n","        # self.T = int(hp.audio.sr * hp.audio.duration) // hp.audio.hop_length + 1\n","        # 10*22050 // 256 + 1 = 862 (blizzard)\n","        # 6*22050 // 256 + 1 = 517 (maestro)\n","        # 6*16000 // 180 + 1 = 534 (voxceleb2)\n","        # 10*16000 // 180 + 1 = 889 (tedlium3)"]},{"cell_type":"code","metadata":{"id":"NdGVXr_o8gdQ"},"source":["class DelayedLSTMAdd(Model):\r\n","  def __init__(self,units,dim_f,dim_t):\r\n","    super(DelayedLSTMAdd,self).__init__()\r\n","    self.w_t = Dense(units)\r\n","    self.w_f = Dense(units)\r\n","\r\n","    self.t_forward = LSTM(units, input_shape=(None, dim_t, units), return_state=True, \r\n","                          return_sequences=True,)\r\n","    \r\n","    self.f_up = LSTM(units, input_shape=(None, dim_f, units), return_state=True,\r\n","                      return_sequences=True)\r\n","    \r\n","    self.f_down = LSTM(units, input_shape=(None, dim_f, units), return_state=True, \r\n","                        return_sequences=True)\r\n","    \r\n","    self.freqstack = LSTM(units, input_shape=(None, dim_f, units), return_state=True, \r\n","                           return_sequences=True)\r\n","    \r\n","\r\n","  def call(self,input_t, input_f):\r\n","    # Extract dimension details.\r\n","    B, F, T, H = input_t.shape\r\n","\r\n","    # reshape time input for parallelization and reshape to initial shape\r\n","    output_t = tf.reshape(input_t,(-1, T, H))\r\n","    output_t = self.t_forward(output_t)[0]\r\n","    output_t = tf.reshape(output_t,(B,F,T,H))\r\n","\r\n","    # transpose input to freq axis, reverse for the reverse lstm\r\n","    # To save memory, i reuse variables to store operation results.\r\n","    f_axis = tf.transpose(input_t,[0,2,1,3])\r\n","    f_axis = tf.reshape(f_axis,(-1,F,H))\r\n","    f_axis = self.f_up(f_axis)[0]\r\n","    f_axis = tf.transpose(tf.reshape(f_axis, (B,T,F,H)), [0,2,1,3])\r\n","    output_t = tf.add(output_t,f_axis)\r\n","\r\n","    #Transpose and reverse frequency axis before running through lstm layer.\r\n","    f_axis = tf.reverse(tf.transpose(input_t, [0,2,1,3]), [2])    \r\n","    f_axis = tf.reshape(f_axis, (-1,F,H))\r\n","    f_axis = self.f_down(f_axis)[0]\r\n","    f_axis = tf.transpose(tf.reshape(f_axis, (B,T,F,H)),[0,2,1,3])\r\n","\r\n","    output_t = tf.add(output_t, f_axis)\r\n","    output_t  = input_t + self.w_t(output_t)\r\n","\r\n","    # Add time lstm output to freq input\r\n","    f = input_f + output_t\r\n","\r\n","    #reshape frequency input.\r\n","    f = tf.transpose(f, [0,2,1,3])\r\n","    f = tf.reshape(f, [-1,F,H])\r\n","    f = self.freqstack(f)[0]\r\n","    f = tf.transpose(tf.reshape(f, [B,T,F,H]), [0,2,1,3])\r\n","    f = input_f  + self.w_f(f)\r\n","\r\n","    return output_t , f\r\n","\r\n","\r\n","\r\n","\r\n","class FeatureExtractorAdd(Model):\r\n","  def __init__(self,units,dim_f,dim_t):\r\n","    super(FeatureExtractorAdd,self).__init__()\r\n","    self.w = Dense(units)\r\n","    self.t_forward = LSTM(units, input_shape=(None, dim_t, units), return_state=True, \r\n","                           return_sequences=True,)\r\n","    \r\n","    self.f_up = LSTM(units, input_shape=(None, dim_f, units), return_state=True,\r\n","                     return_sequences=True)\r\n","    \r\n","    self.f_down = LSTM(units, input_shape=(None, dim_f, units), return_state=True, \r\n","                       return_sequences=True)\r\n","    \r\n","    self.t_backward = LSTM(units, input_shape=(None, dim_t, units), return_state=True, \r\n","                          return_sequences=True)\r\n","    \r\n","\r\n","  def call(self,input_t):\r\n","    # Returns hidden_state of condition.\r\n","    # Extract dimension details.\r\n","    B, F, T, H = input_t.shape\r\n","    #print('input', input_t.shape)\r\n","\r\n","    # Foward Time axis\r\n","    # reshape time input for parallelization and reshape to initial shape\r\n","    hidden = tf.reshape(input_t,(-1, T, H))\r\n","    hidden = self.t_forward(hidden)[0]\r\n","    #print('After', hidden.shape)\r\n","    hidden = tf.reshape(hidden,(B,F,T,H))\r\n","    \r\n","    # Reverse Time axis\r\n","    # Reuse the features variable\r\n","    features = tf.reverse(input_t, [2])\r\n","    features = tf.reshape(features, (-1, T, H))\r\n","    features = self.t_backward(features)[0]\r\n","    features = tf.reshape(features ,(B,F,T,H))\r\n","    hidden = tf.add(hidden , features)\r\n","\r\n","    # transpose input to freq axis, reverse for the reverse lstm\r\n","    # Reuse features variable\r\n","    features = tf.transpose(input_t,[0,2,1,3])\r\n","    features = tf.reshape(features,(-1,F,H))\r\n","    features = self.f_up(features)[0]\r\n","    features = tf.transpose(tf.reshape(features, (B,T,F,H)), [0,2,1,3])\r\n","    hidden = tf.add(hidden,features)\r\n","\r\n","\r\n","    features = tf.reverse(tf.transpose(input_t, [0,2,1,3]), [2])\r\n","    features = tf.reshape(features, (-1,F,H))\r\n","    features = self.f_down(features)[0]\r\n","    features = tf.transpose(tf.reshape(features, (B,T,F,H)),[0,2,1,3])\r\n","    hidden = tf.add(hidden,features)\r\n","\r\n","    # Add residual connection\r\n","    hidden  = input_t + self.w(hidden)\r\n","\r\n","    return hidden\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYOvv92za42n"},"source":["class DelayedLSTM(Model):\n","  def __init__(self,units,dim_f,dim_t):\n","    super(DelayedLSTM,self).__init__()\n","    self.w_t = Dense(units)\n","    self.w_f = Dense(units)\n","\n","    self.t_forward = LSTM(units, input_shape=(None, dim_t, units), return_state=True, \n","                           return_sequences=True,)\n","    \n","    self.f_up = LSTM(units, input_shape=(None, dim_f, units), return_state=True,\n","                      return_sequences=True)\n","    \n","    self.f_down = LSTM(units, input_shape=(None, dim_f, units), return_state=True, \n","                        return_sequences=True)\n","    \n","    self.freqstack = LSTM(units, input_shape=(None, dim_f, units), return_state=True, \n","                          return_sequences=True)\n","    \n","\n","  def call(self,input_t, input_f):\n","    # Extract dimension details.\n","    B, F, T, H = input_t.shape\n","\n","    # reshape time input for parallelization and reshape to initial shape\n","    output_t = tf.reshape(input_t,(-1, T, H))\n","    output_t = self.t_forward(output_t)[0]\n","    output_t = tf.reshape(output_t,(B,F,T,H))\n","\n","    # transpose input to freq axis, reverse for the reverse lstm\n","    # To save memory, i reuse variables to store operation results.\n","    f_axis = tf.transpose(input_t,[0,2,1,3])\n","    f_axis = tf.reshape(f_axis,(-1,F,H))\n","    f_axis = self.f_up(f_axis)[0]\n","    f_axis = tf.transpose(tf.reshape(f_axis, (B,T,F,H)), [0,2,1,3])\n","    output_t = tf.concat([output_t,f_axis], axis=-1)\n","\n","    #Transpose and reverse frequency axis before running through lstm layer.\n","    f_axis = tf.reverse(tf.transpose(input_t, [0,2,1,3]), [2])    \n","    f_axis = tf.reshape(f_axis, (-1,F,H))\n","    f_axis = self.f_down(f_axis)[0]\n","    f_axis = tf.transpose(tf.reshape(f_axis, (B,T,F,H)),[0,2,1,3])\n","\n","    output_t = tf.concat([output_t, f_axis], axis=-1)\n","    output_t  = input_t + self.w_t(output_t)\n","\n","    # Add time lstm output to freq input\n","    f = input_f + output_t\n","\n","    #reshape frequency input.\n","    f = tf.transpose(f, [0,2,1,3])\n","    f = tf.reshape(f, [-1,F,H])\n","    f = self.freqstack(f)[0]\n","    f = tf.transpose(tf.reshape(f, [B,T,F,H]), [0,2,1,3])\n","    f = input_f  + self.w_f(f)\n","\n","    return output_t , f\n","\n","\n","class FeatureExtractor(Model):\n","  def __init__(self,units,dim_f,dim_t):\n","    super(FeatureExtractor,self).__init__()\n","    self.w = Dense(units)\n","    self.t_forward = LSTM(units, input_shape=(None, dim_t, units), return_state=True, \n","                           return_sequences=True,)\n","    \n","    self.f_up = LSTM(units, input_shape=(None, dim_f, units), return_state=True,\n","                    return_sequences=True)\n","    \n","    self.f_down = LSTM(units, input_shape=(None, dim_f, units), return_state=True, \n","                       return_sequences=True)\n","    \n","    self.t_backward = LSTM(units, input_shape=(None, dim_t, units), return_state=True, \n","                           return_sequences=True)\n","    \n","\n","  def call(self,input_t):\n","    # Returns hidden_state of condition.\n","    # Extract dimension details.\n","    B, F, T, H = input_t.shape\n","  \n","\n","    # Foward Time axis\n","    # reshape time input for parallelization and reshape to initial shape\n","    hidden = tf.reshape(input_t,(-1, T, H))\n","    hidden = self.t_forward(hidden)[0]\n","    #print('After', hidden.shape)\n","    hidden = tf.reshape(hidden,(B,F,T,H))\n","    \n","    # Reverse Time axis\n","    # Reuse the features variable\n","    features = tf.reverse(input_t, [2])\n","    features = tf.reshape(features, (-1, T, H))\n","    features = self.t_backward(features)[0]\n","    features = tf.reshape(features ,(B,F,T,H))\n","    hidden = tf.concat([hidden , features], axis=-1)\n","\n","    # transpose input to freq axis, reverse for the reverse lstm\n","    # Reuse features variable\n","    features = tf.transpose(input_t,[0,2,1,3])\n","    features = tf.reshape(features,(-1,F,H))\n","    features = self.f_up(features)[0]\n","    features = tf.transpose(tf.reshape(features, (B,T,F,H)), [0,2,1,3])\n","    #print(features)\n","    hidden = tf.concat([hidden,features], axis=-1)\n","\n","\n","    features = tf.reverse(tf.transpose(input_t, [0,2,1,3]), [2])\n","    features = tf.reshape(features, (-1,F,H))\n","    features = self.f_down(features)[0]\n","    features = tf.transpose(tf.reshape(features, (B,T,F,H)),[0,2,1,3])\n","    #print(features)\n","    hidden = tf.concat([hidden,features], axis=-1)\n","\n","    # Add residual connection\n","    hidden  = input_t + self.w(hidden)\n","    gc.collect()\n","\n","    return hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSB8o0pBPBy_","executionInfo":{"status":"ok","timestamp":1608488930567,"user_tz":360,"elapsed":11877,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"b7e80a5e-cd71-4c31-8267-e1b0203e7709"},"source":["print(gc.get_threshold())\r\n","print(gc.get_count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(700, 10, 10)\n","(44, 5, 8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T8oNOxTl-t_e"},"source":["class TierAdd(Model):\r\n","  def __init__(self,units,dim_f,dim_t,base_tier=True,layers=6,gmm=10):\r\n","    super(TierAdd,self).__init__()\r\n","    self.dims = dim_f, dim_t\r\n","    if base_tier:\r\n","       self.W_t_0 = Dense(units)\r\n","       self.W_f_0 = Dense(units)\r\n","       #self.W_c_0 = nn.Linear(freq, num_hidden)\r\n","       self.tier_layers = [\r\n","          DelayedLSTMAdd(units, dim_f, dim_t) for _ in range(layers)\r\n","      ]\r\n","    else:\r\n","      self.feature_layers = [FeatureExtractorAdd(units,dim_f,dim_t) for _ in range(layers) ]\r\n","      self.tier_layers = [ DelayedLSTMAdd(units,dim_f,dim_t) for _ in range(layers)]\r\n","\r\n","      self.W_t_0 = Dense(units)\r\n","      self.W_f_0 = Dense(units)\r\n","      self.W_feature = Dense(units)\r\n","      self.W_t_ft = Dense(units)\r\n","      self.W_f_ft = Dense(units)\r\n","\r\n","    self.K = gmm\r\n","    # Linear map freqstack_output to produce unconstrained Gaussian Mixture Model parameters \r\n","    self.Wt_theta = Dense(3*self.K)\r\n","    \r\n","\r\n","  def call(self, tier_input,hidden=None):\r\n","    if type(hidden) != None:\r\n","      hidden = self.W_feature(tf.expand_dims(hidden, axis=-1 ))\r\n","      for layer in self.feature_layers:\r\n","        hidden = layer(hidden)\r\n","\r\n","      # Define timestack input:  pad input\r\n","      # Add weighted conditions to it.\r\n","      output_time = self.W_t_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=2),axis=-1)) + self.W_t_ft(hidden)\r\n","      # Define freqstack input: shift input\r\n","      output_freq = self.W_f_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=1),axis=-1)) + self.W_f_ft(hidden)\r\n","      # output_time = output_time + self.W_t_ft(hidden)\r\n","      # output_freq = output_freq + self.W_f_ft(hidden)\r\n","      del hidden   # To save memory, reassign hidden\r\n","\r\n","    else:\r\n","      # Define timestack input:  pad input\r\n","      output_time = self.W_t_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=2),axis=-1))\r\n","      # Define freqstack input: shift input\r\n","      output_freq = self.W_f_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=1),axis=-1))\r\n","\r\n","\r\n","    count = 0\r\n","    for layer in self.tier_layers:\r\n","      output_time, output_freq = layer(output_time, output_freq) \r\n","      count +=1\r\n","\r\n","    theta_hat = self.Wt_theta(output_freq)\r\n","\r\n","    # Calculating mixture gaussian parameters (unconstrained) mu (mean), sigma(std), alpha (probability density fraction):\r\n","\r\n","    mu = theta_hat[..., :self.K] \r\n","    std = theta_hat[..., self.K:2*self.K]\r\n","    alpha = theta_hat[..., 2*self.K:]\r\n","\r\n","    # Convert unconstrained to constrained parameters\r\n","    std = K.exp(std)\r\n","    alpha = K.exp(alpha)\r\n","    alpha = alpha[...,:] / tf.expand_dims(K.sum(alpha, axis=-1),axis=-1)\r\n","    # mixture sum to one: Alpha coefficients for all gaussian distributions must sum to one \r\n","          \r\n","    return mu, std, alpha\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uaQJO0i_i5l3"},"source":["class Tier(Model):\n","  def __init__(self,units,dim_f,dim_t,base_tier=True,layers=6,gmm=10):\n","    super(Tier,self).__init__()\n","    self.dims = dim_f, dim_t\n","    if base_tier:\n","       self.W_t_0 = Dense(units)\n","       self.W_f_0 = Dense(units)\n","       #self.W_c_0 = nn.Linear(freq, num_hidden)\n","       self.tier_layers = [\n","          DelayedLSTM(units, dim_f, dim_t) for _ in range(layers)\n","      ]\n","    else:\n","      self.feature_layers = [FeatureExtractor(units,dim_f,dim_t) for _ in range(layers) ]\n","      self.tier_layers = [ DelayedLSTM(units,dim_f,dim_t) for _ in range(layers)]\n","\n","      self.W_t_0 = Dense(units)\n","      self.W_f_0 = Dense(units)\n","      self.W_feature = Dense(units)\n","      self.W_t_ft = Dense(units)\n","      self.W_f_ft = Dense(units)\n","\n","    self.K = gmm\n","    # Linear map freqstack_output to produce unconstrained Gaussian Mixture Model parameters \n","    self.Wt_theta = Dense(3*self.K)\n","    \n","\n","  def call(self, tier_input,hidden=None):\n","    if type(hidden) != None:\n","      hidden = self.W_feature(tf.expand_dims(hidden, axis=-1 ))\n","      for layer in self.feature_layers:\n","        hidden = layer(hidden)\n","\n","      # Define timestack input:  pad input\n","      # Add weighted conditions to it.\n","      output_time = self.W_t_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=2),axis=-1)) + self.W_t_ft(hidden)\n","      # Define freqstack input: shift input\n","      output_freq = self.W_f_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=1),axis=-1)) + self.W_f_ft(hidden)\n","      # output_time = output_time + self.W_t_ft(hidden)\n","      # output_freq = output_freq + self.W_f_ft(hidden)\n","      del hidden   # To save memory, reassign hidden\n","\n","    else:\n","      # Define timestack input:  pad input\n","      output_time = self.W_t_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=2),axis=-1))\n","      # Define freqstack input: shift input\n","      output_freq = self.W_f_0(tf.expand_dims(tf.roll(tier_input,shift=1, axis=1),axis=-1))\n","\n","\n","    count = 0\n","    for layer in self.tier_layers:\n","      output_time, output_freq = layer(output_time, output_freq) \n","      count +=1\n","\n","    theta_hat = self.Wt_theta(output_freq)\n","\n","    # Calculating mixture gaussian parameters (unconstrained) mu (mean), sigma(std), alpha (probability density fraction):\n","\n","    mu = theta_hat[..., :self.K] \n","    std = theta_hat[..., self.K:2*self.K]\n","    alpha = theta_hat[..., 2*self.K:]\n","\n","    # Convert unconstrained to constrained parameters\n","    std = K.exp(std)\n","    alpha = K.exp(alpha)\n","    alpha = alpha[...,:] / tf.expand_dims(K.sum(alpha, axis=-1),axis=-1)\n","    # mixture sum to one: Alpha coefficients for all gaussian distributions must sum to one \n","\n","    gc.collect()\n","          \n","    return mu, std, alpha\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hg0eOGQQpHb1"},"source":["import pickle\n","\n","def recursive_split_save(data, dest_path, axes, filenames, n_tiers):\n","  axis = axes.pop()\n","  even , odd  = split(data, axis= axis)\n","  # save even and recurse on odd\n","  if len(axes) == 0:\n","    save(even,  odd, dest_path, filenames, n_tiers)\n","    return\n","  else:\n","    return recursive_split_save(odd, dest_path, axes, filenames, (n_tiers - 1))\n","\n","def save(even, odd, dest_path, filenames , n_tiers):\n","  for i in range(odd.shape[0]):\n","    file_sample_path = f'Tier {n_tiers}/samples/{filenames[i]}'\n","    file_feature_path = f'Tier {n_tiers}/features/{filenames[i]}'\n","\n","    with open(os.path.join(dest_path, file_sample_path), 'wb') as f:\n","      pickle.dump(even[i], f)\n","\n","    with open(os.path.join(dest_path,file_feature_path), 'wb') as f:\n","      pickle.dump(odd[i],f)\n","\n","def get_splits(mel, time):\n","  splits = []\n","  for i in range(len(time)):\n","    if i >= len(mel):\n","      splits.append(time[i])\n","    else:\n","      splits.append(mel[i])\n","      splits.append(time[i])\n","  return splits\n","\n","\n","class MelNet(Model):\n","  def __init__(self, units=512 , gmm=10 , mel =256, audio_length=30, sr=22050, window=256, base_tier_dim=(32,50), conditional=False):\n","    super(MelNet,self).__init__()\n","    self.mel_dim = mel\n","    self.base_tier_dim = base_tier_dim\n","    self.conditional = conditional\n","    self.load_tiers(units, gmm, audio_length, sr, window)\n","\n","  def cal_each_tier_dim(self,audio_length, sr=22050, window=256):\n","    # Calculates the dimensions of each tier that makes up the overall melnet model.\n","    self.x_samples = round(audio_length * sr / window ) #+ 1\n","    x_samples = self.x_samples\n","    mel_samples = self.mel_dim\n","    self.mel_splits = []\n","    self.tiers_t_dim=[]\n","    self.time_splits = []\n","    self.tiers_f_dim = []\n","\n","    while (x_samples/2) >= self.base_tier_dim[1]: # while not base tier dim, append 1 or 0 (depending on axis) to list and divide n_of_samples by 2 for each axis\n","      self.time_splits.append(1)\n","      x_samples = x_samples / 2\n","      self.tiers_t_dim.append(x_samples)\n","\n","    while (mel_samples /2) >= self.base_tier_dim[0]:\n","      self.mel_splits.append(0)\n","      mel_samples = mel_samples/2\n","      self.tiers_f_dim.append(mel_samples)\n","\n","    self.tiers_f_dim.reverse()\n","    self.tiers_t_dim.reverse()\n","    #print(self.tiers_f_dim, self.tiers_t_dim)\n","\n","\n","  def call(self, tier_num, x, features=None, batch_size = 16,path='./checkpoints/train'):\n","    # Define optimizer\n","    optimizer = tf.keras.optimizers.Adam()\n","    start_epoch = load_checkpoint(self.tiers[tier_num], optimizer,path)\n","    train(self.tiers[tier_num], x, features,start_epoch, 5, batch_size,)\n","\n","\n","  def sample(self):\n","    pass\n","  \n","  def load_tiers(self, units, gmm, audio_length, sr , window): # Load tiers without weights\n","    self.cal_each_tier_dim(audio_length, sr ,window)\n","    self.tiers = []\n","    for i in range(len(self.time_splits)):\n","      if i == 0:\n","        self.tiers.append(Tier(units, self.tiers_f_dim[i], self.tiers_t_dim[i],gmm=gmm))\n","        self.tiers.append(Tier(units, self.tiers_f_dim[i + 1], self.tiers_t_dim[i], False, layers=5, gmm = gmm))\n","\n","      elif (i+1) >= len(self.tiers_f_dim):\n","        self.tiers.append(Tier(units, self.tiers_f_dim[-1], self.tiers_t_dim[i], False, layers=5, gmm = gmm))\n","      else:\n","        self.tiers.append(Tier(units, self.tiers_f_dim[i], self.tiers_t_dim[i], False, layers=5, gmm = gmm))\n","        self.tiers.append(Tier(units, self.tiers_f_dim[i + 1], self.tiers_t_dim[i], False, layers=5, gmm =gmm))\n","\n","\n","  def process_data(self, dest_path = DESTINATION_PATH, data_dir = DATA_PATH, split_index=0,  batch_size = 8): #process data for just one split for training only to save storage space.\n","    # Calculate splits\n","    splits = get_splits(self.mel_splits, self.time_splits)\n","\n","    # Make directories if not exists.\n","    if not os.path.exists(dest_path):\n","      os.mkdir(dest_path)\n","    \n","    for i in range((len(self.tiers) + 1),0,-1):\n","      tier_dir = os.path.join(dest_path, f'Tier {i}')\n","      sample_dir = os.path.join(dest_path, f'Tier {i}')\n","      if not os.path.exists(tier_dir):\n","        os.mkdir(tier_dir)\n","      if not os.path.exists(sample_dir):\n","        os.mkdir(sample_dir)\n","\n","      if i != 1:\n","        feature_dir = os.path.join(dest_path, f'Tier {i}/features')\n","        if not os.path.exists(feature_dir):\n","          os.mkdir(feature_dir)\n","    \n","    file_list = os.listdir(data_dir)\n","    n_of_samples = len(file_list)\n","    batches = math.ceil(n_of_samples / batch_size) \n","    start =  0\n","    stop = start+ batch_size\n","\n","    # iterate to music samples in folder in batches and split at the particular split index to prepare data for training.\n","    for i in range(batches):\n","      data = np.zeros(shape=(batch_size, self.mel_dim, self.x_samples))\n","      filenames = file_list[start:stop]\n","      for j in file_names:\n","        # Load file\n","        with open(os.path.join(data_dir, j),'rb') as f:\n","          file_loaded = pickle.load(f)\n","        # Append to numpy array 'data'.\n","        data[j] = np.array(file_loaded)\n","      \n","      # Recursively split and save results in respective files.\n","      recursive_split_save(data,dest_path, splits[split_index:], filenames, self.tiers)\n","      start = stop\n","      stop = stop + batch_size\n","\n","    \n","\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TE3WLkGnmd8g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608488932014,"user_tz":360,"elapsed":13275,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"30e309b7-0482-4e36-9c12-fca12e24f578"},"source":["model = MelNet()\n","for tiers in model.tiers:\n","  print(tiers.dims)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(32.0, 80.75)\n","(64.0, 80.75)\n","(64.0, 161.5)\n","(128.0, 161.5)\n","(128.0, 323.0)\n","(128.0, 646.0)\n","(128.0, 1292.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bYFEzhaOidAt"},"source":["# Review this code !!!!\n","from tqdm import tqdm\n","\n","def interleave(base_tier, next_tier, axis=0):\n","  batch, dimf, dimt = base_tier.shape\n","  print(base_tier.shape)\n","  print(next_tier.shape)\n","  \n","  # If axis is 0, fuse along frequency axis\n","  if axis == 0:    \n","    fused_tier = np.zeros(shape=(batch, dimf*2, dimt))\n","    fused_tier[:,:dimf*2:2,:] = base_tier[:,:,:]\n","    fused_tier[:,1:dimf*2:2,:]  = next_tier[:,:,:]\n","  else:\n","    # fuse along time axis\n","    fused_tier = np.zeros(shape=(batch, dimf, dimt*2))\n","    fused_tier[:,:,:dimt*2:2] = base_tier[:,:,:]\n","    fused_tier[:,:,1:dimt*2:2] = next_tier[:,:,:]\n","  \n","  return fused_tier\n","\n","def split(spectogram, axis=0):\n","  # Identify shape and extract length of both axis\n","  f , t = spectogram.shape[1:]\n","\n","  # if split is along frequency axis\n","  if axis == 0:\n","    even = spectogram[:,1:f:2,:]\n","    odd = spectogram[:,:f:2,:]\n","\n","  # else split along the time axis\n","  else:\n","    even = spectogram[:,:,1:t:2]\n","    odd = spectogram[:,:,:t:2]\n","\n","  return even , odd\n","\n","\n","\n","def load_dataset(filenames,feat_files=None, buffer_size=20, batch_size=16):\n","  if feat_files != None:\n","    dataset = tf.data.Dataset.from_tensor_slices((filenames, feat_files))\n","    has_feat = True\n","  else:\n","    dataset = tf.data.Dataset.from_tensor_slices((filenames))\n","    has_feat=False\n","    \n","  # Shuffle and batch\n","  dataset = dataset.shuffle(buffer_size).batch(batch_size)\n","  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","  return dataset, has_feat\n","  \n","def load_checkpoint(tier, optimizer, ckpt_path = \"./checkpoints/train\"):\n","  ckpt = tf.train.Checkpoint(tier,\n","                            optimizer = optimizer)\n","  ckpt_manager = tf.train.CheckpointManager(ckpt, ckpt_path, max_to_keep=5)\n","\n","  start_epoch = 0\n","  if ckpt_manager.latest_checkpoint:\n","    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n","    # restoring the latest checkpoint in checkpoint_path\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","  return start_epoch\n","\n","def train(tier, optimizer, file_train, feat_train = None, start_epoch=0, epochs=5, batch_size=16):\n","  dataset, has_feat = load_dataset(file_train, feat_train, batch_size)\n","  loss_plot = []\n","  num_steps = len(file_train) // batch_size\n","  for epoch in range(start_epoch, epochs):\n","      start = time.time()\n","      total_loss = 0\n","\n","      if has_feat:\n","        for (batch, (spect, feat_spect)) in enumerate(dataset):\n","            batch_loss = train_step(tier, optimizer, spect, feat_spect)\n","            total_loss += batch_loss\n","\n","            # if batch % 15 == 0:\n","            #     print ('Epoch {} Batch {} Loss {:.4f}'.format(\n","            #       epoch + 1, batch, batch_loss.numpy() / int(feat_spect.shape[1])))\n","                \n","      else:\n","        for (batch, spect) in tqdm(enumerate(dataset)):\n","            batch_loss = train_step(tier,optimizer, spect)\n","            total_loss += batch_loss\n","\n","            if batch % 15 == 0:\n","                print ('Epoch {} Batch {} Loss {:.4f}'.format(\n","                  epoch + 1, batch, batch_loss.numpy() / int(feat_spect.shape[1])))\n","\n","              \n","      # storing the epoch end loss value to plot later\n","      loss_plot.append(total_loss / num_steps)\n","\n","      # if epoch % 5 == 0:\n","      #   ckpt_manager.save()\n","\n","      print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n","                                          total_loss/num_steps))\n","      print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n","\n","  return loss_plot\n","\n","\n","def train_step(tier,optimizer, x,features=None ):\n","  loss = 0\n","  with tf.GradientTape() as tape:\n","    if features == None:\n","      mu , std , alpha = tier(x)\n","    else:\n","      mu , std , alpha = tier(x,features)\n","\n","    loss += gaussian_mixture_loss(x, mu, std, alpha)\n","\n","    #total_loss = (loss / int(target.shape[1]))\n","\n","  trainable_variables = tier.trainable_variables\n","\n","  gradients = tape.gradient(loss, trainable_variables)\n","\n","  optimizer.apply_gradients(zip(gradients, trainable_variables))\n","  gc.collect()\n","\n","  return loss #, total_loss\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxZ5cS1FWA_N"},"source":["import gc\n","dimf = 32\n","dimt= 32\n","\n","batch = 4\n","#inputs = tf.random.normal((batch,dimf,dimt))\n","#tier = tf.random.normal((batch,dimf, dimt))\n","#print(inputs[0])\n","#input_t = tf.transpose(inputs,(0,2,1))\n","even , odd = split(tf.random.normal((300,dimf*2,dimt)), axis=0)\n","hidden_units = [64,128,256,512]\n","hidden_losses = []\n","\n","\n","\n","\n","#gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"khHoHcNSut-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608488932019,"user_tz":360,"elapsed":13232,"user":{"displayName":"jeffrey otoibhi","photoUrl":"","userId":"11067368294353522262"}},"outputId":"3d0e5150-b0e1-4735-ec23-15491111d278"},"source":["  hidden_losses"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"NfxAJHP25VB7"},"source":["# for hidden in hidden_units:\r\n","#   lstm = Tier(hidden,dimf,dimt,layers=4,base_tier=False)\r\n","#   #lstm = TierAdd(512, dimf, dimt, layers = 3, base_tier=False)\r\n","#   #lstm_add = DelayedLSTMAdd(512,dimf,dimt)\r\n","#   #lstm(inputs,tier)\r\n","#   adam = tf.keras.optimizers.Adam()\r\n","#   loss = train(lstm, adam, even, odd,epochs=10, batch_size=16)\r\n","#   gc.collect()\r\n","#   hidden_losses.append(loss)\r\n","\r\n","lstm2 = Tier(512,dimf,dimt,layers=4,base_tier=False)\r\n","adam = tf.keras.optimizers.Adam()\r\n","loss = train(lstm2, adam, even, odd,epochs=10, batch_size=16)\r\n","hidden_losses.append(loss)\r\n"],"execution_count":null,"outputs":[]}]}